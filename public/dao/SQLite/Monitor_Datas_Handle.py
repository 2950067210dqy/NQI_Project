import os
import time
from datetime import datetime
from typing import Dict, Any, List

from loguru import logger


from public.config_class.global_setting import global_setting
from public.dao.SQLite.SQliteManager import SQLiteManager
from public.entity.dict.AdvancedFuzzyDict import FuzzyDict
from public.entity.experiment_setting_entity import Experiment_setting_entity
from public.function.DataCaculation import Data_Caculation
from public.function.DataCaculation.Data_Caculation import DataCaculation
from public.function.Modbus.Modbus_Type import Modbus_Slave_Type
# ç›‘æ§æ•°æ®æ“ä½œç±»
from public.util.time_util import time_util
#logger = logger.bind(category="deep_camera_logger")

class Monitor_Datas_Handle():
    def __init__(self,db_name=None):
        # å®éªŒè®¾ç½®
        self.experiment_setting: Experiment_setting_entity = global_setting.get_setting("experiment_setting", None)
        self.experiment_setting_file = global_setting.get_setting("experiment_setting_file", None)
        self.sqlite_manager: SQLiteManager = None
        self.init_construct(db_name)

    def init_construct(self,db_name):
        if db_name is None:
            self.db_name = self.create_db_not_time()
        else:
            self.db_name = db_name
        if self.sqlite_manager is not None:
            self.stop()
        self.sqlite_manager = SQLiteManager(db_name=self.db_name)
        if db_name is None:
            self.create_tables()
        pass

    def stop(self):
        self.sqlite_manager.close()
    def create_db_not_time(self):
        """åˆ›å»ºæ•°æ®åº“ ä¸æŒ‰æ—¶é—´åˆ†åº“ï¼Œç›´æ¥ä¸€ä¸ªå®éªŒä¸€ä¸ªåº“"""
        # è·å–å®éªŒé…ç½®æ–‡ä»¶åç§°
        file_name_without_extension = ""
        experiment_setting_file = global_setting.get_setting("experiment_setting_file", None)
        if experiment_setting_file is not None and os.path.exists(experiment_setting_file):
            # è·å–æ–‡ä»¶åç§°
            file_name = os.path.basename(experiment_setting_file)
            # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åç§°
            file_name_without_extension = os.path.splitext(file_name)[0]
        # å®šä¹‰æ–‡ä»¶å¤¹è·¯å¾„
        folder_path = os.getcwd() + global_setting.get_setting('monitor_data')['STORAGE']['fold_path'] + os.path.join(

            global_setting.get_setting('monitor_data')['STORAGE']['sub_fold_path'],
            f"{file_name_without_extension}_{time_util.get_format_file_from_time(global_setting.get_setting('start_experiment_time', time.time()))}",
            f'data'
        )

        # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(folder_path, exist_ok=True)
        db_name = f"data.db"
        db_file_path = os.path.join(folder_path, db_name)
        return db_file_path
    def create_db(self):
        """
        åˆ›å»ºæ•°æ®åº“
        :return:
        """
        year, month, day, hour, minute, second = time_util.get_current_times_info()
        # è·å–å®éªŒé…ç½®æ–‡ä»¶åç§°
        file_name_without_extension =""
        experiment_setting_file = global_setting.get_setting("experiment_setting_file", None)
        if experiment_setting_file is not None and os.path.exists(experiment_setting_file):
            # è·å–æ–‡ä»¶åç§°
            file_name = os.path.basename(experiment_setting_file)
            # ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶åç§°
            file_name_without_extension = os.path.splitext(file_name)[0]
        # å®šä¹‰æ–‡ä»¶å¤¹è·¯å¾„
        folder_path =os.getcwd()+ global_setting.get_setting('monitor_data')['STORAGE']['fold_path'] + os.path.join(

            global_setting.get_setting('monitor_data')['STORAGE']['sub_fold_path'], f"{file_name_without_extension}_{time_util.get_format_file_from_time(global_setting.get_setting('start_experiment_time',time.time()))}",f'{year}', f'{month}')

        # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(folder_path, exist_ok=True)
        db_name = f"{day}.db"
        db_file_path = os.path.join(folder_path, db_name)
        return db_file_path

    def create_tables(self):
        if self.experiment_setting is not None:

            gids = [group.id for group in self.experiment_setting.groups ]
            # å®ä¾‹åŒ–ç›¸æœºæ•°æ®é¡¹é¡¹çš„æ•°æ®è¡¨
            for data_type in Modbus_Slave_Type.Cameras.value:
                # æ¯ä¸ªé¼ ç¬¼éƒ½è¦å®ä¾‹åŒ–ï¼Œé™¤äº†å‚è€ƒæ°”è·¯
                for carge_number in gids:
                    for table_name_short in data_type.value['table']:
                        # åˆ—
                        columns = {item[0]: item[2] for item in data_type.value['table'][table_name_short]['column']}
                        # è¡¨åç§°
                        table_name = f"{data_type.value['name']}_{table_name_short}_cage_{carge_number}"
                        # åˆ›å»ºè¡¨
                        if not self.sqlite_manager.is_exist_table(table_name):
                            self.sqlite_manager.create_table(table_name,
                                                             columns)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºæ•°æ®è¡¨{table_name}æˆåŠŸï¼")
                        # åˆ›å»ºè¯¥è¡¨æè¿°çš„è¡¨
                        table_meta_name = f"{table_name}_meta"
                        # ä¸å­˜åœ¨åˆ™åˆ›å»ºå’Œæ’å…¥
                        if not self.sqlite_manager.is_exist_table(table_meta_name):
                            self.sqlite_manager.create_meta_table(table_meta_name)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºè¡¨ç»“æ„æè¿°æ•°æ®è¡¨{table_meta_name}æˆåŠŸï¼")
                            # æ’å…¥æè¿°ä¿¡æ¯
                            for item in data_type.value['table'][table_name_short]['column']:
                                self.sqlite_manager.insert_or_ignore(table_meta_name, item_name=item[0],
                                                                     item_struct=item[2],
                                                                     description=item[1])
            # å®ä¾‹åŒ–æ¯è½®æ¬¡æ•°æ®è¡¨
            for data_type in Modbus_Slave_Type.Epochs.value:
                # æ·»åŠ cage_0 ç»™å‚è€ƒæ°”å­˜å‚¨æ•°æ® è¿™é‡Œçš„-1ä»£è¡¨æ€»è½®æ¬¡è¡¨ï¼Œè¡¨åä¸ºEpoch_data_all ä¸å¸¦åé¢çš„cage_-1
                for carge_number in [-1,int(global_setting.get_setting('configer')['mouse_cage']['reference'])]+gids:
                    for table_name_short in data_type.value['table']:
                        # åˆ—
                        columns = {item[0]: item[2] for item in data_type.value['table'][table_name_short]['column']}
                        # è¡¨åç§°
                        # æ€»è¡¨ è¡¨åä¸ºEpoch_data_all ä¸å¸¦åé¢çš„cage_-1
                        if carge_number ==-1:
                            table_name = f"{data_type.value['name']}_{table_name_short}_all"
                        else:
                            table_name = f"{data_type.value['name']}_{table_name_short}_cage_{carge_number}"
                        # åˆ›å»ºè¡¨
                        if not self.sqlite_manager.is_exist_table(table_name):
                            self.sqlite_manager.create_table(table_name,
                                                             columns)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºæ•°æ®è¡¨{table_name}æˆåŠŸï¼")
                        # åˆ›å»ºè¯¥è¡¨æè¿°çš„è¡¨
                        table_meta_name = f"{table_name}_meta"
                        # ä¸å­˜åœ¨åˆ™åˆ›å»ºå’Œæ’å…¥
                        if not self.sqlite_manager.is_exist_table(table_meta_name):
                            self.sqlite_manager.create_meta_table(table_meta_name)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºè¡¨ç»“æ„æè¿°æ•°æ®è¡¨{table_meta_name}æˆåŠŸï¼")
                            # æ’å…¥æè¿°ä¿¡æ¯
                            for item in data_type.value['table'][table_name_short]['column']:
                                self.sqlite_manager.insert_or_ignore(table_meta_name, item_name=item[0], item_struct=item[2],
                                                           description=item[1])

            # å®ä¾‹åŒ–å…¶ä»–æ•°æ®é¡¹çš„æ•°æ®è¡¨
            for data_type in Modbus_Slave_Type.Calibrations.value:
                for table_name_short in data_type.value['table']:
                    # åˆ—
                    columns = {item[0]: item[2] for item in data_type.value['table'][table_name_short]['column']}
                    # è¡¨åç§°
                    table_name = f"{data_type.value['name']}_{table_name_short}"
                    # åˆ›å»ºè¡¨
                    if not self.sqlite_manager.is_exist_table(table_name):
                        self.sqlite_manager.create_table(table_name,
                                                         columns)
                        # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºæ•°æ®è¡¨{table_name}æˆåŠŸï¼")
                    # åˆ›å»ºè¯¥è¡¨æè¿°çš„è¡¨
                    table_meta_name = f"{table_name}_meta"
                    # ä¸å­˜åœ¨åˆ™åˆ›å»ºå’Œæ’å…¥
                    if not self.sqlite_manager.is_exist_table(table_meta_name):
                        self.sqlite_manager.create_meta_table(table_meta_name)
                        # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºè¡¨ç»“æ„æè¿°æ•°æ®è¡¨{table_meta_name}æˆåŠŸï¼")
                        # æ’å…¥æè¿°ä¿¡æ¯
                        for item in data_type.value['table'][table_name_short]['column']:
                            self.sqlite_manager.insert_or_ignore(table_meta_name, item_name=item[0], item_struct=item[2],
                                                       description=item[1])
            # å®ä¾‹åŒ–å…¬å…±ä¼ æ„Ÿå™¨æ•°æ®çš„æ•°æ®è¡¨
            for data_type in Modbus_Slave_Type.Not_Each_Mouse_Cage.value:
                # æ·»åŠ cage_8 ç»™å‚è€ƒæ°”å­˜å‚¨æ•°æ®
                for carge_number in [int(global_setting.get_setting('configer')['mouse_cage']['reference'])]+gids:
                    for table_name_short in data_type.value['table']:
                        # åˆ—
                        columns = {item[0]: item[2] for item in data_type.value['table'][table_name_short]['column']}
                        # è¡¨åç§°
                        table_name = f"{data_type.value['name']}_{table_name_short}_cage_{carge_number}"
                        # åˆ›å»ºè¡¨
                        if not self.sqlite_manager.is_exist_table(table_name):
                            self.sqlite_manager.create_table(table_name,
                                                             columns)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºæ•°æ®è¡¨{table_name}æˆåŠŸï¼")
                        # åˆ›å»ºè¯¥è¡¨æè¿°çš„è¡¨
                        table_meta_name = f"{table_name}_meta"
                        # ä¸å­˜åœ¨åˆ™åˆ›å»ºå’Œæ’å…¥
                        if not self.sqlite_manager.is_exist_table(table_meta_name):
                            self.sqlite_manager.create_meta_table(table_meta_name)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºè¡¨ç»“æ„æè¿°æ•°æ®è¡¨{table_meta_name}æˆåŠŸï¼")
                            # æ’å…¥æè¿°ä¿¡æ¯
                            for item in data_type.value['table'][table_name_short]['column']:
                                self.sqlite_manager.insert_or_ignore(table_meta_name, item_name=item[0], item_struct=item[2],
                                                           description=item[1])
                pass
        # å®ä¾‹åŒ–æ¯ä¸ªç¬¼å­é‡Œçš„ä¼ æ„Ÿå™¨çš„æ•°æ®è¡¨

            for data_type in Modbus_Slave_Type.Each_Mouse_Cage.value:
                for carge_number in gids:
                    for table_name_short in data_type.value['table']:
                        # åˆ—
                        columns = {item[0]: item[2] for item in data_type.value['table'][table_name_short]['column']}
                        # è¡¨åç§°
                        table_name = f"{data_type.value['name']}_{table_name_short}_cage_{carge_number}"
                        # åˆ›å»ºè¡¨
                        if not self.sqlite_manager.is_exist_table(table_name):
                            self.sqlite_manager.create_table(table_name,
                                                             columns)
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºæ•°æ®è¡¨{table_name}æˆåŠŸï¼")
                        # åˆ›å»ºè¯¥è¡¨æè¿°çš„è¡¨
                        table_meta_name = f"{table_name}_meta"
                        # ä¸å­˜åœ¨åˆ™åˆ›å»ºå’Œæ’å…¥
                        if not self.sqlite_manager.is_exist_table(table_meta_name):
                            # logger.info(f"æ•°æ®åº“{self.db_name}åˆ›å»ºè¡¨ç»“æ„æè¿°æ•°æ®è¡¨{table_meta_name}æˆåŠŸï¼")
                            self.sqlite_manager.create_meta_table(table_meta_name)
                            # æ’å…¥æè¿°ä¿¡æ¯
                            for item in data_type.value['table'][table_name_short]['column']:
                                self.sqlite_manager.insert(table_meta_name, item_name=item[0], item_struct=item[2],
                                                           description=item[1])
        pass

    def _map_data_compact_with_none(self,data_list, columns_mapping):
        """
        æˆ‘çš„columns_all_except_idåˆ—è¡¨è£…ç€æˆ‘æ•°æ®è¡¨çš„æ‰€æœ‰åˆ—åä»¥åŠåˆ—çš„æè¿°ï¼Œä¾‹å¦‚[{'åºå·':'id'}.......],
        ç°åœ¨æˆ‘çš„data['data']æ‹¥æœ‰æ•°æ® [
            {'desc': 'æ¸©åº¦æµ‹é‡å€¼(â„ƒ)', 'value': -85.9},
            {'desc': 'æ¹¿åº¦æµ‹é‡å€¼(%RH)', 'value': 93.9},
            {'desc': 'å™ªå£°æµ‹é‡å€¼(dB)', 'value': 190.1},
            {'desc': 'å¤§æ°”å‹æµ‹é‡å€¼(KPa)', 'value': 2275.6},
            {'desc': 'å½“å‰è®¡é‡å‘¨æœŸå†…è·‘è½®åœˆæ•°æµ‹é‡å€¼', 'value': 8501.028},
            {'desc': 'å¤‡æ³¨', 'value': None}
        ],
        æˆ‘è¯¥æ€ä¹ˆæ ¹æ®data['data']é‡Œçš„åˆ—çš„æè¿°descå»columns_all_except_idæ‰¾ç€å¯¹åº”çš„åˆ—åï¼Œ
        å¹¶ä¸”å°†data['data']é‡Œdescæ‰€åœ¨å­—å…¸çš„'value'é”®çš„å€¼ä¸æˆ‘ä»¬æ‰€æ‰¾ç€å¯¹åº”çš„åˆ—åç»™å½¢æˆé”®å€¼å¯¹çš„å­—å…¸ï¼Œ
        ä¾‹å¦‚{'id':0},å¦‚æœdata['data']æ²¡æœ‰åœ¨columns_all_except_idæ‰¾ç€å¯¹åº”çš„åˆ—åï¼Œ
        åˆ™å°†é”®å€¼å¯¹åˆ—åçš„å€¼ä¸ºNone
        :param data_list:
        :param columns_mapping:
        :return:è¾“å‡º: {'id': None, 'temperature': -85.9, 'humidity': 93.9, 'noise': 190.1, 'pressure': 2275.6, 'wheel_count': 8501.028, 'remarks': None, 'other_field': None}
        """
        # åˆ›å»ºæè¿°åˆ°åˆ—åçš„æ˜ å°„
        desc_to_column = columns_mapping

        # åˆ›å»ºæ•°æ®çš„æè¿°åˆ°å€¼çš„æ˜ å°„ æ¨¡ç³ŠæŸ¥è¯¢ å› ä¸ºå¯èƒ½é”®ä¼šæœ‰ç»†å¾®å·®å¼‚
        desc_to_value =FuzzyDict({item['desc']: item['value'] for item in data_list})

        # ä¸ºæ‰€æœ‰åˆ—åˆ›å»ºæ˜ å°„
        result = {column: desc_to_value.fuzzy_get(desc) for desc, column in desc_to_column.items()}

        return result
    def insert_data(self, data):
        """

        :param data:
        :return: success ï¼šæ˜¯å¦æˆåŠŸ, error é”™è¯¯ä¿¡æ¯
        """


        # æ·»åŠ æ•°æ®åˆ°è¡¨é‡Œ
        if data is not None:
            # logger.critical(f"{data}")
            # æ¸…æ´—æ•°æ®
            for data_item in data['data']:
                if isinstance(data_item['value'],list) and len(data_item['value']) ==0:
                    data_item['value'] =None
            # å…¬å…±ä¼ æ„Ÿå™¨ï¼š
            if data['mouse_cage_number'] == -1:
                # è·å–è¯¥è¡¨åç§°
                table_name = f"{data['module_name']}_{data['table_name']}"
                # # è·å–è¯¥è¡¨çš„columné¡¹
                table_name_meta = f"{table_name}_meta"
                columns_query = self.sqlite_manager.query(table_name_meta)
                # æŠŠidåˆ—å»æ‰ å› ä¸ºidè‡ªå¢
                columns_all_except_id = {i[2]:i[0] for i in columns_query if i[0] != 'id' }
                data_store = self._map_data_compact_with_none(data['data'], columns_all_except_id)
                data_store['time'] = data['time']
                # logger.critical(f"{data}|||{columns_all_except_id}|||{data_store}")
                result = self.sqlite_manager.insert(table_name, **data_store)
                if result == 1:
                    logger.info(f"æ•°æ®æ’å…¥è¡¨{table_name}æˆåŠŸï¼")
                    return True, None
                else:
                    logger.info(f"æ•°æ®æ’å…¥è¡¨{table_name}å¤±è´¥ï¼")
                    return False, f"æ•°æ®æ’å…¥è¡¨{table_name}å¤±è´¥ï¼"

            else:  # æ¯ä¸ªé¼ ç¬¼ä¼ æ„Ÿå™¨ä»¥åŠæ°”è·¯ä¼ æ„Ÿå™¨å’Œæ¯è½®æ¬¡æ•°æ®ï¼š
                # è·å–è¯¥è¡¨åç§°
                table_name = f"{data['module_name']}_{data['table_name']}_cage_{data['mouse_cage_number']}"
                # # è·å–è¯¥è¡¨çš„columné¡¹
                table_name_meta = f"{table_name}_meta"
                columns_query = self.sqlite_manager.query(table_name_meta)
                # æŠŠidåˆ—å»æ‰ å› ä¸ºidè‡ªå¢
                columns_all_except_id = {i[2]:i[0] for i in columns_query if i[0] != 'id' }
                data_store = self._map_data_compact_with_none(data['data'], columns_all_except_id)
                data_store['time'] = data['time']
                # logger.critical(f"{data}|||{columns_all_except_id}|||{data_store}")
                result = self.sqlite_manager.insert(table_name, **data_store)
                if result == 1:
                    logger.info(f"æ•°æ®æ’å…¥è¡¨{table_name}æˆåŠŸï¼")
                    return True, None
                else:
                    logger.info(f"æ•°æ®æ’å…¥è¡¨{table_name}å¤±è´¥ï¼")
                    return False, f"æ•°æ®æ’å…¥è¡¨{table_name}å¤±è´¥ï¼"
        else:
            return False
            pass

    def query_data(self, table_name):
        """
        è·å–æ•°æ®åº“çš„æ•°æ®è¡¨çš„å•è¡Œæœ€æ–°çš„æ•°æ®
        :param table_name:
        :return:
        """
        results_query = self.sqlite_manager.query_current_Data(table_name)
        columns_query = self.sqlite_manager.query(f"{table_name}_meta")
        return_data = []
        results = []
        columns = []
        if results_query is not None and len(results_query) > 0:
            # ä¸è¦id å’Œtime
            results = list(results_query[0])[1:-1]
        if columns_query is not None and len(columns_query) > 0:
            # ä¸è¦id å’Œtime
            columns = [i[2] for i in columns_query][1:-1]
        for value, description in zip(results, columns):
            return_data.append({'desc': description, 'value': value})
        return return_data
        pass
    def query_data_all(self, table_name):
        """
        è·å–æ•°æ®åº“çš„æ•°æ®è¡¨çš„æ‰€æœ‰çš„æ•°æ®
        :param table_name:
        :return:
        """
        results_query = self.sqlite_manager.query(table_name)

        results = []

        if results_query is not None and len(results_query) > 0:
            results = results_query
        return results
        pass
    def query_data_counts(self, table_name):
        """
        è·å–æ•°æ®åº“çš„æ•°æ®è¡¨çš„æ‰€æœ‰çš„æ•°æ®çš„æ•°é‡
        :param table_name:
        :return:
        """
        results_query = self.sqlite_manager.query_counts_conditions(table_name)

        results = 0

        if results_query is not None:
            results = results_query
        return results
        pass
    def query_data_paging(self, table_name,rows_per_page,start_row):
        """
        è·å–æ•°æ®åº“çš„æ•°æ®è¡¨çš„åˆ†é¡µçš„æ•°æ®
        :param table_name:
        :param rows_per_page:æ¯ä¸€é¡µå‡ è¡Œ
        :param start_row:ç¬¬å‡ è¡Œå¼€å§‹
        :return:
        """
        results_query = self.sqlite_manager.query_paging(table_name,rows_per_page,start_row)

        results = []

        if results_query is not None and len(results_query) > 0:
            results = results_query
        return results
        pass
    def query_current_one_data(self,table_name):
        results_query = self.sqlite_manager.query_current_Data(table_name)

        return_results = None

        if results_query is not None and len(results_query) > 0:
            results = results_query[0]
            # å¯»æ‰¾åˆ—å
            columns_query_result = self.sqlite_manager.query(f"{table_name}_meta")
            if columns_query_result is not None and len(columns_query_result) > 0:
                columns_query =[i[0] for i in columns_query_result]
                # logger.critical(f"columns_query:{columns_query},columns_query_result:{columns_query_result}")
                return_results=dict(zip(columns_query, results))
                return return_results
            else:
                return return_results

        else:
            return return_results
    def query_data_one_column_current(self, table_name, columns_flag):
        """
        è·å–æŒ‡å®šåˆ—çš„å•ä¸ªæœ€æ–°çš„æ•°æ®
        :param table_name:
        :param columns_flag:
        :return:
        """
        if len(columns_flag) > 0:
            conditions = "  where "
        else:
            conditions = ""
        for columns_signle in columns_flag:
            if columns_signle == columns_flag[-1]:
                conditions += f" item_name = '{columns_signle}' "
            else:
                conditions += f" item_name = '{columns_signle}' or "
        columns_query = self.sqlite_manager.query_conditions(f"{table_name}_meta", conditions)

        results_query = self.sqlite_manager.query_current_Data_columns(table_name, [i[0] for i in columns_query])
        return_data = {}
        results = []
        columns_name = []
        columns_desc = []
        if results_query is not None and len(results_query) > 0:
            results = list(results_query[0])
        if columns_query is not None and len(columns_query) > 0:
            columns_name = [i[0] for i in columns_query]
            columns_desc = [i[2] for i in columns_query]
            pass
        for value, column_name, column_desc in zip(results, columns_name, columns_desc):
            return_data[column_name] = {'desc': column_desc, 'value': value}
        """\
        return_data
        {
            'temperature':{
            'desc':'æ¸©åº¦',
            'value':1
            },
            .....
        }
        """
        return [return_data]

    def query_meta_table_data(self, table_name):
        """
        è·å–è¡¨ç»“æ„æ•°æ® item_desc å»é™¤id remarks timeåˆ—
        :param table_name:
        :return:
        """
        columns_query = self.sqlite_manager.query(f"{table_name}_meta")
        columns_desc = []
        if columns_query is not None and len(columns_query) > 0:
            columns_desc = [{'desc':i[2],'name':i[0]} for i in columns_query][1:-2]
        return columns_desc

    def query_meta_table_data_all(self, table_name):
        """
        è·å–è¡¨ç»“æ„æ•°æ® item_desc
        :param table_name:
        :return:
        """
        columns_query = self.sqlite_manager.query(f"{table_name}_meta")
        columns_desc = []
        if columns_query is not None and len(columns_query) > 0:
            columns_desc = [{'desc': i[2], 'name': i[0]} for i in columns_query]
        return columns_desc

    def query_monitor_data_all_tables_paging(self, page: int = 1,
            page_size: int = 100,all_column_datas=[])-> dict:
        """
        :param page ç¬¬å‡ é¡µ
        :param page_size æ¯é¡µå¤šå°‘
        :param all_column_datas ç”¨æˆ·é€‰æ‹©çš„åˆ—æ•°æ®
        :return:æŠŠä¼ å…¥çš„è¡¨æŒ‰ time å­—æ®µè”ç«‹å¹¶åˆ†é¡µè¿”å›ç»“æœï¼Œè¿”å›å­—å…¸åŒ…å«:
          - total_items: æ€»è¡Œæ•°ï¼ˆtime çš„å¹¶é›†å¤§å°ï¼‰
          - total_pages
          - page (å®é™…è¿”å›é¡µï¼Œ1-based)
          - page_size
          - columns: åˆ—ååˆ—è¡¨ï¼ˆä¸ rows ä¸­ dict çš„ key å¯¹åº”ï¼‰
          - rows: åˆ—è¡¨ï¼Œæ¯è¡Œä¸º dictï¼ˆkey=åˆ—å, value=å€¼ï¼‰

        ä» SQLite æ•°æ®åº“ä¸­æ‰¾å‡ºæ‰€æœ‰è¡¨åï¼ˆæ’é™¤åç§°ä¸­åŒ…å« "meta" çš„è¡¨ï¼Œå¤§å°å†™ä¸æ•æ„Ÿï¼‰ï¼›
        ä»…ä¿ç•™åŒ…å« time å­—æ®µçš„è¡¨ï¼›
        å°†è¿™äº›è¡¨æŒ‰ time è”ç«‹ï¼ˆä»¥ time çš„å¹¶é›†ä¸ºä¸»ï¼‰ï¼ŒæŠŠå„è¡¨çš„å…¶å®ƒå­—æ®µå¹¶åˆ—ï¼ˆåˆ«åä¸º è¡¨å__åˆ—åï¼Œé¿å…é‡åï¼‰ï¼›
        æ”¯æŒåˆ†é¡µï¼ˆpage 1-basedï¼Œpage_sizeï¼‰ï¼Œå¹¶è¿”å›æ€»æ¡æ•°ã€æ€»é¡µæ•°ã€å½“å‰é¡µæ•°æ®ç­‰åˆ†é¡µä¿¡æ¯ã€‚
        æ³¨æ„äº‹é¡¹ï¼š

            SQLite æ²¡æœ‰ FULL OUTER JOINï¼Œæ‰€ä»¥ç”¨ UNION æŠŠå„è¡¨çš„ time åˆå¹¶æˆä¸€ä¸ªæ´¾ç”Ÿè¡¨ all_timesï¼Œç„¶å LEFT JOIN æ¯ä¸ªè¡¨ï¼›
            ä¸ºé˜²æ­¢ SQL æ³¨å…¥ä¸æ ‡è¯†ç¬¦å†²çªï¼Œå¯¹è¡¨åä¸åˆ—åä½¿ç”¨åŒå¼•å·è½¬ä¹‰ï¼ˆquote_identï¼‰ï¼›
            ç»Ÿè®¡æ€»æ¡æ•°æ—¶ä½¿ç”¨ SELECT COUNT(*) FROM ( ... UNION ... )ï¼›
            LIMIT / OFFSET ç”¨äºåˆ†é¡µï¼ˆpage ä» 1 å¼€å§‹ï¼‰ã€‚å¦‚æœæ•°æ®é‡å¾ˆå¤§ï¼ŒCOUNT ä¸ UNION å¯èƒ½è¾ƒæ…¢ï¼Œå»ºè®®ä¸º time åˆ—å»ºç´¢å¼•æˆ–åœ¨åç«¯åˆ†ç‰‡

        """
        if len(all_column_datas) == 0:
            return {}
        tables = self.sqlite_manager.get_tables_with_time(exclude_substr=["meta","Epoch_data"],columns=['time'])
        result = self.sqlite_manager.query_joined_by_time( tables, page=page, page_size=page_size, order_asc=True)

        result_title = ["æ—¶é—´"]

        # æ‰¾åˆ°ä¸­æ–‡åˆ—å
        for columns in result["columns"][1:]:
            columns_split = columns.split('__')
            table_name = columns_split[0]
            column_name = columns_split[1]
            columns_query =self.sqlite_manager.query_conditions(table_name=f"{table_name}_meta", conditions=f" where item_name='{column_name}'")
            print(columns_query,table_name,column_name)
            result_title.append(columns_query[0][2])
        result["columns_title"]=result_title
        # print("å‚ä¸è”ç«‹çš„è¡¨:", tables)
        # print(
        #     f"æ€»æ¡æ•°: {result['total_items']}, æ€»é¡µæ•°: {result['total_pages']}, å½“å‰é¡µ: {result['page']}, æ¯é¡µ: {result['page_size']}")
        # print("åˆ—:", result["columns"])
        # print("ç¤ºä¾‹è¡Œï¼ˆæœ€å¤š 10 è¡Œï¼‰:")
        # for i, row in enumerate(result["rows"][:10]):
        #     print(i + 1, row)

        if len(result) == 0:
            return {}
        # caculation_handle = DataCaculation(sqlite_manager = self.sqlite_manager)
        #
        # return_results = caculation_handle.caculate_data(columns=all_column_datas,datas=result)


        return result
        pass
    def query_epoch_data_all_tables_paging(self,gid:int=0, page: int = 1,
            page_size: int = 100,all_column_datas=[])-> dict:
        """
        :param gid é¼ ç¬¼/é€šé“å‡ çš„æ•°æ®  å¦‚æœä¸º-1 åˆ™è·å–æ€»è¡¨Epoch_data_allçš„æ•°æ®
        :param page ç¬¬å‡ é¡µ
        :param page_size æ¯é¡µå¤šå°‘
        :param all_column_datas ç”¨æˆ·é€‰æ‹©çš„åˆ—æ•°æ®
        :return:æŠŠä¼ å…¥çš„è¡¨æŒ‰ time å­—æ®µè”ç«‹å¹¶åˆ†é¡µè¿”å›ç»“æœï¼Œè¿”å›å­—å…¸åŒ…å«:
          - total_items: æ€»è¡Œæ•°ï¼ˆtime çš„å¹¶é›†å¤§å°ï¼‰
          - total_pages
          - page (å®é™…è¿”å›é¡µï¼Œ1-based)
          - page_size
          - columns: åˆ—ååˆ—è¡¨ï¼ˆä¸ rows ä¸­ dict çš„ key å¯¹åº”ï¼‰
          - rows: åˆ—è¡¨ï¼Œæ¯è¡Œä¸º dictï¼ˆkey=åˆ—å, value=å€¼ï¼‰

        ä» SQLite æ•°æ®åº“ä¸­æ‰¾å‡ºepoch_Dataï¼›

        æ”¯æŒåˆ†é¡µï¼ˆpage 1-basedï¼Œpage_sizeï¼‰ï¼Œå¹¶è¿”å›æ€»æ¡æ•°ã€æ€»é¡µæ•°ã€å½“å‰é¡µæ•°æ®ç­‰åˆ†é¡µä¿¡æ¯ã€‚
        æ³¨æ„äº‹é¡¹ï¼š

            SQLite æ²¡æœ‰ FULL OUTER JOINï¼Œæ‰€ä»¥ç”¨ UNION æŠŠå„è¡¨çš„ time åˆå¹¶æˆä¸€ä¸ªæ´¾ç”Ÿè¡¨ all_timesï¼Œç„¶å LEFT JOIN æ¯ä¸ªè¡¨ï¼›
            ä¸ºé˜²æ­¢ SQL æ³¨å…¥ä¸æ ‡è¯†ç¬¦å†²çªï¼Œå¯¹è¡¨åä¸åˆ—åä½¿ç”¨åŒå¼•å·è½¬ä¹‰ï¼ˆquote_identï¼‰ï¼›
            ç»Ÿè®¡æ€»æ¡æ•°æ—¶ä½¿ç”¨ SELECT COUNT(*) FROM ( ... UNION ... )ï¼›
            LIMIT / OFFSET ç”¨äºåˆ†é¡µï¼ˆpage ä» 1 å¼€å§‹ï¼‰ã€‚å¦‚æœæ•°æ®é‡å¾ˆå¤§ï¼ŒCOUNT ä¸ UNION å¯èƒ½è¾ƒæ…¢ï¼Œå»ºè®®ä¸º time åˆ—å»ºç´¢å¼•æˆ–åœ¨åç«¯åˆ†ç‰‡

        """
        if len(all_column_datas) == 0:
            return {}
        # å¦‚æœä¸º-1 åˆ™è·å–æ€»è¡¨Epoch_data_allçš„æ•°æ®
        if gid == -1:
            table_name = f"Epoch_data_all"
            pass
        else:
            table_name = f"Epoch_data_cage_{gid}"
        result = self.sqlite_manager.query_Epoch_datas( table_name, page=page, page_size=page_size, order_asc=True )
        result_title = []

        # æ‰¾åˆ°ä¸­æ–‡åˆ—å
        for columns in result["columns"]:

            columns_query =self.sqlite_manager.query_conditions(table_name=f"{table_name}_meta", conditions=f" where item_name='{columns}'")
            if columns_query and len(columns_query) > 0:
                result_title.append(columns_query[0][2])
        result["columns_title"]=result_title
        # print("å‚ä¸è”ç«‹çš„è¡¨:", tables)
        # print(
        #     f"æ€»æ¡æ•°: {result['total_items']}, æ€»é¡µæ•°: {result['total_pages']}, å½“å‰é¡µ: {result['page']}, æ¯é¡µ: {result['page_size']}")
        # print("åˆ—:", result["columns"])
        # print("ç¤ºä¾‹è¡Œï¼ˆæœ€å¤š 10 è¡Œï¼‰:")
        # for i, row in enumerate(result["rows"][:10]):
        #     print(i + 1, row)
        # logger.critical(result)
        if len(result) == 0:
            return {}
        # caculation_handle = DataCaculation(sqlite_manager = self.sqlite_manager)
        #
        # return_results = caculation_handle.caculate_data(columns=all_column_datas,datas=result)

        return result

        pass
    def query_monitor_data_all_tables(self, all_column_datas=[]) -> dict:
        pass


    def query_data_in_line_with_epoch_data(self,start_time,end_time):
        # æ‰¾å‡ºå½“å‰æ—¶é—´æ®µçš„æ‰€æœ‰æ•°æ®è¡¨çš„æ•°æ®é™¤äº†metaè¡¨
        tables = self.sqlite_manager.get_tables_with_time(exclude_substr=["meta","Epoch_data"],columns=['time'])
        # logger.critical(tables)
        # æ‰§è¡ŒæŸ¥è¯¢
        results, columns = self.sqlite_manager.get_multi_table_data(tables,
            start_time, end_time, join_type="separate"
        )
        # logger.critical(results)
        # logger.critical(columns)
        return results, columns

        pass

    """
    @author wangjie
    @create_time 2025-11-27
    @start
    """
    def get_available_cages(self):
        """
        è·å–æ•°æ®åº“ä¸­å­˜åœ¨çš„é¼ ç¬¼ç¼–å·åˆ—è¡¨

        Returns:
            list: æ’åºåçš„é¼ ç¬¼ç¼–å·åˆ—è¡¨
        """
        try:
            logger.info("=== å¼€å§‹è·å–å¯ç”¨é¼ ç¬¼åˆ—è¡¨ ===")

            # è·å–æ‰€æœ‰è¡¨å
            tables = self.sqlite_manager.get_all_tables()
            logger.info(f"æ•°æ®åº“ä¸­æ€»å…±æ‰¾åˆ° {len(tables)} ä¸ªè¡¨:")
            for table in tables:
                logger.info(f"  è¡¨å: {table}")

            cage_numbers = []
            for table_name in tables:
                logger.info(f"æ£€æŸ¥è¡¨: {table_name}")

                if table_name.startswith("MouseDeepPosition_data_cage_") and not table_name.endswith("_meta"):
                    logger.info(f"  åŒ¹é…çš„é¼ ç¬¼è¡¨: {table_name}")
                    # æå–é¼ ç¬¼ç¼–å·
                    cage_number = table_name.replace("MouseDeepPosition_data_cage_", "")
                    logger.info(f"  æå–çš„é¼ ç¬¼ç¼–å·å­—ç¬¦ä¸²: '{cage_number}'")

                    try:
                        cage_num = int(cage_number)
                        cage_numbers.append(cage_num)
                        logger.info(f"  æˆåŠŸè½¬æ¢ä¸ºæ•°å­—: {cage_num}")
                    except ValueError as e:
                        logger.error(f"  æ— æ³•è½¬æ¢ä¸ºæ•°å­—: {e}")
                        continue

            result = sorted(cage_numbers)
            logger.info(f"æœ€ç»ˆæ‰¾åˆ°çš„é¼ ç¬¼ç¼–å·: {result}")
            return result

        except Exception as e:
            logger.error(f"è·å–å¯ç”¨é¼ ç¬¼åˆ—è¡¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    # def get_trajectory_data(self, cage_id, start_time=None, end_time=None, limit=None):
    #     """
    #     è·å–æŒ‡å®šé¼ ç¬¼çš„è½¨è¿¹æ•°æ®
    #
    #     Args:
    #         cage_id (int): é¼ ç¬¼ç¼–å·
    #         start_time (str, optional): å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼: 'YYYY-MM-DD HH:MM:SS'
    #         end_time (str, optional): ç»“æŸæ—¶é—´ï¼Œæ ¼å¼: 'YYYY-MM-DD HH:MM:SS'
    #         limit (int, optional): é™åˆ¶è¿”å›çš„æ•°æ®æ¡æ•°
    #
    #     Returns:
    #         dict: åŒ…å«è½¨è¿¹æ•°æ®çš„å­—å…¸
    #     """
    #     try:
    #         print(f"=== å¼€å§‹è·å–é¼ ç¬¼ {cage_id} çš„è½¨è¿¹æ•°æ® ===")
    #
    #         table_name = f"MouseDeepPosition_data_cage_{cage_id}"
    #
    #         # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    #         if not self.sqlite_manager.check_table_exists(table_name):
    #             return {
    #                 'success': False,
    #                 'data': [],
    #                 'total_count': 0,
    #                 'message': f'é¼ ç¬¼ {cage_id} çš„æ•°æ®è¡¨ä¸å­˜åœ¨'
    #             }
    #
    #         # è·å–æ€»æ•°æ®æ¡æ•°
    #         total_count = self.sqlite_manager.get_table_data_count(table_name, start_time, end_time)
    #         print(f"è¡¨ {table_name} ä¸­ç¬¦åˆæ¡ä»¶çš„æ•°æ®æ€»æ•°: {total_count}")
    #
    #         # è·å–XYZè½¨è¿¹æ•°æ®
    #         rows = self.sqlite_manager.get_trajectory_xyz_data_by_table(
    #             table_name, start_time=start_time, end_time=end_time, limit=limit
    #         )
    #
    #         print(f"å®é™…è·å–åˆ° {len(rows)} æ¡è½¨è¿¹æ•°æ®")
    #
    #         # è½¬æ¢æ•°æ®æ ¼å¼
    #         trajectory_data = []
    #         for row in rows:
    #             time_val, x, y, z = row
    #             trajectory_data.append([
    #                 time_val,
    #                 float(x) if x is not None else 0.0,
    #                 float(y) if y is not None else 0.0,
    #                 float(z) if z is not None else 0.0
    #             ])
    #
    #         if len(trajectory_data) > 0:
    #             print(f"æ•°æ®ç¤ºä¾‹ - å‰3æ¡:")
    #             for i, data_point in enumerate(trajectory_data[:3]):
    #                 print(
    #                     f"  {i + 1}: æ—¶é—´={data_point[0]}, x={data_point[1]:.2f}, y={data_point[2]:.2f}, z={data_point[3]:.2f}")
    #
    #         return {
    #             'success': True,
    #             'data': trajectory_data,
    #             'total_count': total_count,
    #             'message': f'æˆåŠŸè·å– {len(trajectory_data)} æ¡è½¨è¿¹æ•°æ®'
    #         }
    #
    #     except Exception as e:
    #         error_msg = f"è·å–è½¨è¿¹æ•°æ®å¤±è´¥: {e}"
    #         print(error_msg)
    #         import traceback
    #         traceback.print_exc()
    #         return {
    #             'success': False,
    #             'data': [],
    #             'total_count': 0,
    #             'message': error_msg
    #         }
    """
    @author wangjie
    @create_time 2025-11-27
    @end
    """


    """
    @author wangjie
    @create_time 2025-12-01
    @start
    """
    def get_trajectory_data(self, cage_id, limit=None):
        """
        è·å–æŒ‡å®šé¼ ç¬¼çš„è½¨è¿¹æ•°æ®

        Args:
            cage_id (int): é¼ ç¬¼ç¼–å·
            limit (int, optional): é™åˆ¶è¿”å›çš„æ•°æ®æ¡æ•°

        Returns:
            dict: åŒ…å«è½¨è¿¹æ•°æ®å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        try:
            logger.info(f"=== å¼€å§‹è·å–é¼ ç¬¼ {cage_id} çš„è½¨è¿¹æ•°æ® ===")

            table_name = f"MouseDeepPosition_data_cage_{cage_id}"

            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not self.sqlite_manager.check_table_exists(table_name):
                return {
                    'success': False,
                    'data': [],
                    'total_count': 0,
                    'message': f'é¼ ç¬¼ {cage_id} çš„æ•°æ®è¡¨ä¸å­˜åœ¨'
                }

            # è·å–æ€»æ•°æ®æ¡æ•°
            total_count = self.sqlite_manager.get_table_data_count(table_name)
            logger.info(f"è¡¨ {table_name} ä¸­çš„æ•°æ®æ€»æ•°: {total_count}")

            # è·å–XYZè½¨è¿¹æ•°æ® - æ³¨æ„è¿™é‡Œä¸è¦æŸ¥è¯¢timeåˆ—
            rows = self.sqlite_manager.get_trajectory_xyz_data(table_name, limit=limit)

            # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿ rows ä¸æ˜¯ None
            if rows is None:
                logger.error("âš ï¸ è­¦å‘Šï¼šæŸ¥è¯¢è¿”å›äº† None")
                rows = []

            logger.info(f"å®é™…è·å–åˆ° {len(rows)} æ¡è½¨è¿¹æ•°æ®")

            # è½¬æ¢æ•°æ®æ ¼å¼
            trajectory_data = []
            valid_count = 0
            null_count = 0

            for row in rows:
                try:
                    image_name, x, y, z = row

                    # å¤„ç†nullå€¼
                    x_val = float(x) if x is not None else None
                    y_val = float(y) if y is not None else None
                    z_val = float(z) if z is not None else None

                    if x_val is not None and y_val is not None and z_val is not None:
                        valid_count += 1
                    else:
                        null_count += 1

                    trajectory_data.append([
                        image_name,
                        x_val,
                        y_val,
                        z_val
                    ])
                except Exception as row_error:
                    logger.error(f"å¤„ç†æ•°æ®è¡Œæ—¶å‡ºé”™: {row}, é”™è¯¯: {row_error}")
                    continue

            logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: æ€»å…± {len(trajectory_data)} æ¡, æœ‰æ•ˆ {valid_count} æ¡, null {null_count} æ¡")

            if len(trajectory_data) > 0:
                logger.info(f"æ•°æ®ç¤ºä¾‹ - å‰3æ¡:")
                for i, data_point in enumerate(trajectory_data[:3]):
                    try:
                        x_str = f"{data_point[1]:.3f}" if data_point[1] is not None else "null"
                        y_str = f"{data_point[2]:.3f}" if data_point[2] is not None else "null"
                        z_str = f"{data_point[3]:.3f}" if data_point[3] is not None else "null"
                        logger.info(f"  {i + 1}: å›¾åƒ={data_point[0]}, x={x_str}, y={y_str}, z={z_str}")
                    except Exception as e:
                        logger.error(f"  {i + 1}: æ•°æ®æ ¼å¼é”™è¯¯: {data_point}")

            return {
                'success': True,
                'data': trajectory_data,
                'total_count': len(trajectory_data),
                'valid_count': valid_count,
                'null_count': null_count,
                'message': f'æˆåŠŸè·å– {len(trajectory_data)} æ¡è½¨è¿¹æ•°æ® (æœ‰æ•ˆ: {valid_count}, æ— æ•ˆ: {null_count})'
            }

        except Exception as e:
            error_msg = f"è·å–è½¨è¿¹æ•°æ®å¤±è´¥: {e}"
            logger.error(error_msg)
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'data': [],
                'total_count': 0,
                'message': error_msg
            }

    """
    @author wangjie
    @create_time 2025-12-01
    @end
    """